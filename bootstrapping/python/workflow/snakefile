# Adding the configuration file.
configfile: "./workflow/config.yaml"

# import module common from path: "../../../../common"
import importlib.util
import sys, os
spec = importlib.util.spec_from_file_location("parsers", "../common/parsers.py")
parsers = importlib.util.module_from_spec(spec)
sys.modules["parsers"] = parsers
spec.loader.exec_module(parsers)

# The path for the filtering.
FILTER_PATH = "./workflow/filter.txt"

# Color stuff.
def red(text):
    return("\033[91m{}\033[00m".format(text))

def green(text):
    return("\033[92m{}\033[00m".format(text))

def yellow(text):
    return("\033[93m{}\033[00m".format(text))

def blue(text):
    return("\033[94m{}\033[00m".format(text))

# importing stuff
import os

# the specification of the provided features
# Grabbing the features which are in a RDA format.
specs = glob_wildcards("../../data/features/{cell_line}/{feature_type}/{file_name}")
def italic(text):
    return("\033[3m{}\033[00m".format(text))

# Getting all the values from the wildcards
CELL_LINES = specs.cell_line
FEATURE_TYPES = specs.feature_type
FILE_NAMES = specs.file_name
features = list(zip(CELL_LINES, FEATURE_TYPES, FILE_NAMES))
before_ = len(features)
features = parsers.parse_filter_file(FILTER_PATH).filter(features)
print(f"{yellow('Filtering done: ')} from {before_} features to {len(features)} features. (total {yellow(-len(features) + before_)} removed)")
print("\nUsing this files:")
for cell_line, feature_type, file_name in features:
    print(f"{red(cell_line)}-{yellow(feature_type)} ({italic(file_name)})")

# Reading the thing from the configuration file.
BOOTSTRAPS = config["bootstraps"]
print()
print("Running Python Pipeline with {} bootstraps".format(yellow(BOOTSTRAPS)))
print()

# Computing the pvalues.
rule compute_pvalue:
    input:
        counts = [f"../../data/counts/{cell_line}/{feature_type}/{file_name}.counts.tsv" for cell_line, feature_type, file_name in features],
        files = [f"../../data/features/{cell_line}/{feature_type}/{file_name}" for cell_line, feature_type, file_name in features]
    params:
        bootstraps = BOOTSTRAPS
    
    benchmark:
        "../benchmarks/compute_pvalue.benchmark.txt"
    
    output:
        files = [f"../../results/{cell_line}.{feature_type}.tsv" for cell_line, feature_type, file_name in features]
    run:
        for cell_line, feature_type, file_name in features:
            print(f"Computing pvalues for {red(cell_line)}-{yellow(feature_type)} ({italic(file_name)})")
           
            ### The file containing the counts. (--counts)
            counts_file = f"../../data/counts/{cell_line}/{feature_type}/{file_name}.counts.tsv"

            ### The file containing the features. (--features)
            features_file = f"../../data/features/{cell_line}/{feature_type}/{file_name}"

            ### The folder containing the clusters. (--clusters)
            clusters_file = f"../../data/clusters/{cell_line}/"

            ### The output tsv file (--output)
            output_file = f"../../results/{cell_line}.{feature_type}.tsv"
            
            ### Running the file
            shell(f"python main.py -a {counts_file} -f {features_file} -o {output_file} -n {BOOTSTRAPS} -c {clusters_file}")
            print("Saved to: {}".format(blue(output_file)))
            print()

# Annotating the files.
rule annotate_features:
    input: 
        files = [f"../../data/features/{cell_line}/{feature_type}/{file_name}" for cell_line, feature_type, file_name in features]
    output:
        files = [f"../../data/counts/{cell_line}/{feature_type}/{file_name}.counts.tsv" for cell_line, feature_type, file_name in features]
    
    benchmark:
        "../benchmarks/annotate_features.benchmark.txt"
    
    run:
        for cell_line, feature_type, file_name in features:
            print(f"Annotating {red(cell_line)}-{yellow(feature_type)} ({italic(file_name)})")
            in_file = f"../../data/features/{cell_line}/{feature_type}/{file_name}"
            out_file = f"../../data/counts/{cell_line}/{feature_type}/{file_name}.counts.tsv"

            # Checking if it exists already (this is done because snakemake deletes the file for no reason if nothing has changed)
            if(os.path.exists(out_file)):
                print(f"{green(out_file)} already exists, skipping")
                continue

            # Generating it.
            shell(f"Rscript annotate.R -i {in_file} -o {out_file} -a ../../data/annotations/")